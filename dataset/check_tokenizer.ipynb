{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0510 21:16:53.965119 140539081692928 file_utils.py:41] PyTorch version 1.4.0 available.\n",
      "I0510 21:16:55.096747 140539081692928 file_utils.py:57] TensorFlow version 2.1.0 available.\n"
     ]
    }
   ],
   "source": [
    "from transformers import *\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet = \"just waking up...ahh i have a headache\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_text = \"headache\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0510 21:16:55.345454 140539081692928 tokenization_utils.py:420] Model name 'transformers_vocab/albert-large-v2-spiece.model' not found in model shortcut name list (albert-base-v1, albert-large-v1, albert-xlarge-v1, albert-xxlarge-v1, albert-base-v2, albert-large-v2, albert-xlarge-v2, albert-xxlarge-v2). Assuming 'transformers_vocab/albert-large-v2-spiece.model' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "W0510 21:16:55.346103 140539081692928 tokenization_utils.py:432] Calling AlbertTokenizer.from_pretrained() with the path to a single file or url is deprecated\n",
      "I0510 21:16:55.346552 140539081692928 tokenization_utils.py:502] loading file transformers_vocab/albert-large-v2-spiece.model\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AlbertTokenizer.from_pretrained(\n",
    "            pretrained_model_name_or_path=\"transformers_vocab/albert-large-v2-spiece.model\",\n",
    "            lowercase=True,\n",
    "            add_prefix_space=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_text_copy = \"\".join(selected_text.split())\n",
    "tweet_copy = \"\".join(tweet.split())\n",
    "\n",
    "len_st = len(selected_text_copy)\n",
    "idx0 = None\n",
    "idx1 = None\n",
    "\n",
    "for ind in (i for i, e in enumerate(tweet_copy) if e == selected_text_copy[0]):\n",
    "    if tweet_copy[ind: ind + len_st] == selected_text_copy:\n",
    "        idx0 = ind\n",
    "        idx1 = ind + len_st - 1\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'headache'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_text_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_targets = [0] * len(tweet_copy)\n",
    "if idx0 != None and idx1 != None:\n",
    "    for ct in range(idx0, idx1 + 1):\n",
    "        char_targets[ct] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids_orig = tokenizer.encode(tweet)\n",
    "input_ids_orig = input_ids_orig[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "just (0, 4)\n",
      "waking (4, 10)\n",
      "up (10, 12)\n",
      ". (12, 13)\n",
      ". (13, 14)\n",
      ". (14, 15)\n",
      "ah (15, 17)\n",
      "h (17, 18)\n",
      "i (18, 19)\n",
      "have (19, 23)\n",
      "a (23, 24)\n",
      "headache (24, 32)\n"
     ]
    }
   ],
   "source": [
    "tweet_offsets = []\n",
    "idx = 0\n",
    "for t in input_ids_orig:\n",
    "    w = tokenizer.decode([t])\n",
    "    print(w, (idx, idx + len(w)))\n",
    "    tweet_offsets.append((idx, idx + len(w)))\n",
    "    idx += len(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_idx = []\n",
    "for j, (offset1, offset2) in enumerate(tweet_offsets):\n",
    "    if sum(char_targets[offset1: offset2]) > 0:\n",
    "        target_idx.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[11]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_start = target_idx[0]\n",
    "targets_end = target_idx[-1]\n",
    "tweet_copy = \"\".join(tweet.split())\n",
    "\n",
    "# ... i kinda lost respect  . i kinda lost respect\n",
    "prediction = \"\"\n",
    "for ix in range(targets_start, targets_end + 1):\n",
    "    prediction += tweet_copy[tweet_offsets[ix][0]: tweet_offsets[ix][1]]\n",
    "    if (ix + 1) < len(tweet_offsets) and tweet_offsets[ix][1] < tweet_offsets[ix + 1][0]:\n",
    "        prediction += \" \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'headache'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_prediction = len(prediction)\n",
    "\n",
    "for ind in (i for i, e in enumerate(tweet) if e == prediction[0]):\n",
    "    \n",
    "    tweet_sub_sentence = \"\".join(tweet[ind:].split())\n",
    "    \n",
    "    if tweet_sub_sentence[:len_prediction] == prediction:\n",
    "        orig_idx0 = ind\n",
    "        break\n",
    "        \n",
    "for ind in range(orig_idx0, len(tweet)):\n",
    "\n",
    "    if \"\".join(tweet[orig_idx0: ind+1].split()) == prediction:\n",
    "        filtered_output = tweet[orig_idx0: ind+1]\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "headache headache\n"
     ]
    }
   ],
   "source": [
    "print(selected_text, filtered_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3env",
   "language": "python",
   "name": "py3env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
