
Loading data...
*General Setting*
seed: 42
model: TweetBert
trainable parameters:129,375,755
model's state_dict:
device: cuda
use gpu: True
device num: 2
optimizer: AdamW (
Parameter Group 0
    betas: (0.9, 0.999)
    correct_bias: True
    eps: 1e-08
    initial_lr: 1e-05
    lr: 0.0
    weight_decay: 0.001

Parameter Group 1
    betas: (0.9, 0.999)
    correct_bias: True
    eps: 1e-08
    initial_lr: 0.0002
    lr: 0.0
    weight_decay: 0.001

Parameter Group 2
    betas: (0.9, 0.999)
    correct_bias: True
    eps: 1e-08
    initial_lr: 1e-05
    lr: 0.0
    weight_decay: 0.0

Parameter Group 3
    betas: (0.9, 0.999)
    correct_bias: True
    eps: 1e-08
    initial_lr: 0.0002
    lr: 0.0
    weight_decay: 0.0
)
reuse model: False
adversarial training: False
** start training here! **
   batch_size=16,  accumulation_steps=1
   experiment  = ['training-k-fold-bert-v2.py']
Epoch0

lr: 0.000071 train loss: 2.495598 train_jaccard: 0.559862 train_jaccard_postprocessing: 0.978431 train_jaccard_no_postprocessing: 0.249096 train_ans_acc: 0.548814 train_noise_acc: 0.963047
lr: 0.000104 train loss: 1.231007 train_jaccard: 0.591341 train_jaccard_postprocessing: 0.977672 train_jaccard_no_postprocessing: 0.306112 train_ans_acc: 0.540374 train_noise_acc: 0.981524
lr: 0.000103 train loss: 1.041389 train_jaccard: 0.611610 train_jaccard_postprocessing: 0.974580 train_jaccard_no_postprocessing: 0.344294 train_ans_acc: 0.559763 train_noise_acc: 0.987682
validation loss: 0.627408 eval_jaccard: 0.683612 eval_jaccard_postprocessing: 0.972674 eval_jaccard_no_postprocessing: 0.479230 eval_ans_acc: 0.860237 eval_noise_acc: 1.000000
Validation metric improved (-inf --> 0.683612).  Saving model ...Model saved as /media/jionie/my_disk/Kaggle/Tweet/model/TweetBert/roberta-base-42/fold_3/458_step_0_epoch.pth.lr: 0.000102 train loss: 0.926409 train_jaccard: 0.622675 train_jaccard_postprocessing: 0.973095 train_jaccard_no_postprocessing: 0.369227 train_ans_acc: 0.618385 train_noise_acc: 0.990762
lr: 0.000100 train loss: 0.818792 train_jaccard: 0.632867 train_jaccard_postprocessing: 0.973260 train_jaccard_no_postprocessing: 0.388325 train_ans_acc: 0.670347 train_noise_acc: 0.992609
lr: 0.000099 train loss: 0.767852 train_jaccard: 0.643152 train_jaccard_postprocessing: 0.972945 train_jaccard_no_postprocessing: 0.402755 train_ans_acc: 0.703923 train_noise_acc: 0.993841
validation loss: 0.514975 eval_jaccard: 0.699919 eval_jaccard_postprocessing: 0.972674 eval_jaccard_no_postprocessing: 0.507066 eval_ans_acc: 0.872247 eval_noise_acc: 1.000000
Validation metric improved (0.683612 --> 0.699919).  Saving model ...Model saved as /media/jionie/my_disk/Kaggle/Tweet/model/TweetBert/roberta-base-42/fold_3/916_step_0_epoch.pth.lr: 0.000098 train loss: 0.798762 train_jaccard: 0.648782 train_jaccard_postprocessing: 0.972519 train_jaccard_no_postprocessing: 0.415320 train_ans_acc: 0.728298 train_noise_acc: 0.994721
lr: 0.000096 train loss: 0.791054 train_jaccard: 0.652108 train_jaccard_postprocessing: 0.971346 train_jaccard_no_postprocessing: 0.422452 train_ans_acc: 0.746407 train_noise_acc: 0.995381
lr: 0.000095 train loss: 0.758270 train_jaccard: 0.656276 train_jaccard_postprocessing: 0.971199 train_jaccard_no_postprocessing: 0.431707 train_ans_acc: 0.762216 train_noise_acc: 0.995894
lr: 0.000094 train loss: 0.760629 train_jaccard: 0.659184 train_jaccard_postprocessing: 0.970444 train_jaccard_no_postprocessing: 0.436953 train_ans_acc: 0.773038 train_noise_acc: 0.996305
validation loss: 0.504990 eval_jaccard: 0.706265 eval_jaccard_postprocessing: 0.972674 eval_jaccard_no_postprocessing: 0.517899 eval_ans_acc: 0.878617 eval_noise_acc: 1.000000
Validation metric improved (0.699919 --> 0.706265).  Saving model ...Model saved as /media/jionie/my_disk/Kaggle/Tweet/model/TweetBert/roberta-base-42/fold_3/1374_step_0_epoch.pth.Epoch1

lr: 0.000092 train loss: 0.706473 train_jaccard: 0.713021 train_jaccard_postprocessing: 0.974284 train_jaccard_no_postprocessing: 0.519047 train_ans_acc: 0.880931 train_noise_acc: 1.000000
lr: 0.000091 train loss: 0.727605 train_jaccard: 0.703942 train_jaccard_postprocessing: 0.970068 train_jaccard_no_postprocessing: 0.510558 train_ans_acc: 0.875228 train_noise_acc: 1.000000
lr: 0.000090 train loss: 0.709070 train_jaccard: 0.704913 train_jaccard_postprocessing: 0.970760 train_jaccard_no_postprocessing: 0.512154 train_ans_acc: 0.880474 train_noise_acc: 1.000000
validation loss: 0.497547 eval_jaccard: 0.703600 eval_jaccard_postprocessing: 0.972674 eval_jaccard_no_postprocessing: 0.513351 eval_ans_acc: 0.871884 eval_noise_acc: 1.000000
lr: 0.000088 train loss: 0.688358 train_jaccard: 0.709205 train_jaccard_postprocessing: 0.969587 train_jaccard_no_postprocessing: 0.519551 train_ans_acc: 0.877623 train_noise_acc: 1.000000
lr: 0.000087 train loss: 0.719791 train_jaccard: 0.709196 train_jaccard_postprocessing: 0.969798 train_jaccard_no_postprocessing: 0.520214 train_ans_acc: 0.875821 train_noise_acc: 1.000000
lr: 0.000086 train loss: 0.721914 train_jaccard: 0.707574 train_jaccard_postprocessing: 0.968732 train_jaccard_no_postprocessing: 0.519334 train_ans_acc: 0.876597 train_noise_acc: 1.000000
validation loss: 0.490467 eval_jaccard: 0.706819 eval_jaccard_postprocessing: 0.972674 eval_jaccard_no_postprocessing: 0.518846 eval_ans_acc: 0.878981 eval_noise_acc: 1.000000
Validation metric improved (0.706265 --> 0.706819).  Saving model ...Model saved as /media/jionie/my_disk/Kaggle/Tweet/model/TweetBert/roberta-base-42/fold_3/2290_step_1_epoch.pth.lr: 0.000084 train loss: 0.701776 train_jaccard: 0.707239 train_jaccard_postprocessing: 0.969681 train_jaccard_no_postprocessing: 0.518335 train_ans_acc: 0.877346 train_noise_acc: 1.000000
lr: 0.000083 train loss: 0.700533 train_jaccard: 0.706125 train_jaccard_postprocessing: 0.970086 train_jaccard_no_postprocessing: 0.515568 train_ans_acc: 0.876654 train_noise_acc: 1.000000
lr: 0.000082 train loss: 0.716571 train_jaccard: 0.704681 train_jaccard_postprocessing: 0.970288 train_jaccard_no_postprocessing: 0.515869 train_ans_acc: 0.878903 train_noise_acc: 1.000000
lr: 0.000080 train loss: 0.696269 train_jaccard: 0.705487 train_jaccard_postprocessing: 0.970403 train_jaccard_no_postprocessing: 0.516521 train_ans_acc: 0.877920 train_noise_acc: 1.000000
validation loss: 0.480781 eval_jaccard: 0.710520 eval_jaccard_postprocessing: 0.972674 eval_jaccard_no_postprocessing: 0.525164 eval_ans_acc: 0.872066 eval_noise_acc: 1.000000
Validation metric improved (0.706819 --> 0.710520).  Saving model ...Model saved as /media/jionie/my_disk/Kaggle/Tweet/model/TweetBert/roberta-base-42/fold_3/2748_step_1_epoch.pth.Epoch2

lr: 0.000079 train loss: 0.645543 train_jaccard: 0.730598 train_jaccard_postprocessing: 0.972981 train_jaccard_no_postprocessing: 0.546231 train_ans_acc: 0.882755 train_noise_acc: 1.000000
lr: 0.000078 train loss: 0.659432 train_jaccard: 0.731488 train_jaccard_postprocessing: 0.973343 train_jaccard_no_postprocessing: 0.552424 train_ans_acc: 0.876369 train_noise_acc: 1.000000
lr: 0.000076 train loss: 0.670211 train_jaccard: 0.726299 train_jaccard_postprocessing: 0.974612 train_jaccard_no_postprocessing: 0.546478 train_ans_acc: 0.882299 train_noise_acc: 1.000000
validation loss: 0.485237 eval_jaccard: 0.708390 eval_jaccard_postprocessing: 0.972674 eval_jaccard_no_postprocessing: 0.521527 eval_ans_acc: 0.876979 eval_noise_acc: 1.000000
lr: 0.000075 train loss: 0.674079 train_jaccard: 0.724266 train_jaccard_postprocessing: 0.975026 train_jaccard_no_postprocessing: 0.544507 train_ans_acc: 0.882071 train_noise_acc: 1.000000
lr: 0.000074 train loss: 0.690455 train_jaccard: 0.721567 train_jaccard_postprocessing: 0.972483 train_jaccard_no_postprocessing: 0.543660 train_ans_acc: 0.880383 train_noise_acc: 1.000000
lr: 0.000072 train loss: 0.644084 train_jaccard: 0.722572 train_jaccard_postprocessing: 0.970989 train_jaccard_no_postprocessing: 0.547065 train_ans_acc: 0.880170 train_noise_acc: 1.000000
validation loss: 0.479364 eval_jaccard: 0.714199 eval_jaccard_postprocessing: 0.972674 eval_jaccard_no_postprocessing: 0.531444 eval_ans_acc: 0.870246 eval_noise_acc: 1.000000
Validation metric improved (0.710520 --> 0.714199).  Saving model ...Model saved as /media/jionie/my_disk/Kaggle/Tweet/model/TweetBert/roberta-base-42/fold_3/3664_step_2_epoch.pth.lr: 0.000071 train loss: 0.636271 train_jaccard: 0.723450 train_jaccard_postprocessing: 0.970873 train_jaccard_no_postprocessing: 0.548951 train_ans_acc: 0.881843 train_noise_acc: 1.000000
lr: 0.000070 train loss: 0.652683 train_jaccard: 0.722588 train_jaccard_postprocessing: 0.970648 train_jaccard_no_postprocessing: 0.546839 train_ans_acc: 0.880874 train_noise_acc: 1.000000
lr: 0.000068 train loss: 0.639349 train_jaccard: 0.722436 train_jaccard_postprocessing: 0.969975 train_jaccard_no_postprocessing: 0.547385 train_ans_acc: 0.880779 train_noise_acc: 1.000000
lr: 0.000067 train loss: 0.618926 train_jaccard: 0.724336 train_jaccard_postprocessing: 0.970547 train_jaccard_no_postprocessing: 0.548383 train_ans_acc: 0.881934 train_noise_acc: 1.000000
validation loss: 0.479414 eval_jaccard: 0.712493 eval_jaccard_postprocessing: 0.972674 eval_jaccard_no_postprocessing: 0.528532 eval_ans_acc: 0.872429 eval_noise_acc: 1.000000
Epoch3

lr: 0.000066 train loss: 0.612913 train_jaccard: 0.732392 train_jaccard_postprocessing: 0.970653 train_jaccard_no_postprocessing: 0.560388 train_ans_acc: 0.889599 train_noise_acc: 1.000000
lr: 0.000064 train loss: 0.646457 train_jaccard: 0.729931 train_jaccard_postprocessing: 0.969720 train_jaccard_no_postprocessing: 0.561474 train_ans_acc: 0.880703 train_noise_acc: 1.000000
lr: 0.000063 train loss: 0.605472 train_jaccard: 0.735107 train_jaccard_postprocessing: 0.970638 train_jaccard_no_postprocessing: 0.568338 train_ans_acc: 0.880627 train_noise_acc: 1.000000
validation loss: 0.488857 eval_jaccard: 0.709460 eval_jaccard_postprocessing: 0.972674 eval_jaccard_no_postprocessing: 0.523354 eval_ans_acc: 0.882075 eval_noise_acc: 1.000000
lr: 0.000062 train loss: 0.616863 train_jaccard: 0.734123 train_jaccard_postprocessing: 0.970014 train_jaccard_no_postprocessing: 0.568014 train_ans_acc: 0.881045 train_noise_acc: 1.000000
lr: 0.000060 train loss: 0.595597 train_jaccard: 0.736999 train_jaccard_postprocessing: 0.970727 train_jaccard_no_postprocessing: 0.572583 train_ans_acc: 0.882573 train_noise_acc: 1.000000
lr: 0.000059 train loss: 0.610027 train_jaccard: 0.736977 train_jaccard_postprocessing: 0.970281 train_jaccard_no_postprocessing: 0.571528 train_ans_acc: 0.883136 train_noise_acc: 1.000000
validation loss: 0.485480 eval_jaccard: 0.713321 eval_jaccard_postprocessing: 0.972674 eval_jaccard_no_postprocessing: 0.529946 eval_ans_acc: 0.872066 eval_noise_acc: 1.000000
lr: 0.000058 train loss: 0.639132 train_jaccard: 0.736653 train_jaccard_postprocessing: 0.970364 train_jaccard_no_postprocessing: 0.570581 train_ans_acc: 0.882430 train_noise_acc: 1.000000
lr: 0.000056 train loss: 0.620936 train_jaccard: 0.735594 train_jaccard_postprocessing: 0.969854 train_jaccard_no_postprocessing: 0.570167 train_ans_acc: 0.883212 train_noise_acc: 1.000000
lr: 0.000055 train loss: 0.584588 train_jaccard: 0.737574 train_jaccard_postprocessing: 0.970291 train_jaccard_no_postprocessing: 0.571763 train_ans_acc: 0.883364 train_noise_acc: 1.000000
lr: 0.000054 train loss: 0.614951 train_jaccard: 0.737156 train_jaccard_postprocessing: 0.970432 train_jaccard_no_postprocessing: 0.570665 train_ans_acc: 0.883440 train_noise_acc: 1.000000
validation loss: 0.486161 eval_jaccard: 0.711816 eval_jaccard_postprocessing: 0.972674 eval_jaccard_no_postprocessing: 0.527375 eval_ans_acc: 0.882439 eval_noise_acc: 1.000000
Epoch4

lr: 0.000052 train loss: 0.574408 train_jaccard: 0.756654 train_jaccard_postprocessing: 0.976166 train_jaccard_no_postprocessing: 0.599957 train_ans_acc: 0.890967 train_noise_acc: 1.000000
lr: 0.000051 train loss: 0.565677 train_jaccard: 0.754536 train_jaccard_postprocessing: 0.970293 train_jaccard_no_postprocessing: 0.600810 train_ans_acc: 0.886861 train_noise_acc: 1.000000
lr: 0.000049 train loss: 0.596780 train_jaccard: 0.747592 train_jaccard_postprocessing: 0.970580 train_jaccard_no_postprocessing: 0.588315 train_ans_acc: 0.883364 train_noise_acc: 1.000000
validation loss: 0.491418 eval_jaccard: 0.714704 eval_jaccard_postprocessing: 0.972674 eval_jaccard_no_postprocessing: 0.532306 eval_ans_acc: 0.880801 eval_noise_acc: 1.000000
Validation metric improved (0.714199 --> 0.714704).  Saving model ...Model saved as /media/jionie/my_disk/Kaggle/Tweet/model/TweetBert/roberta-base-42/fold_3/5954_step_4_epoch.pth.lr: 0.000048 train loss: 0.587892 train_jaccard: 0.749530 train_jaccard_postprocessing: 0.969972 train_jaccard_no_postprocessing: 0.591430 train_ans_acc: 0.884352 train_noise_acc: 1.000000
lr: 0.000047 train loss: 0.560153 train_jaccard: 0.750445 train_jaccard_postprocessing: 0.970406 train_jaccard_no_postprocessing: 0.592601 train_ans_acc: 0.883303 train_noise_acc: 1.000000
lr: 0.000045 train loss: 0.603376 train_jaccard: 0.749891 train_jaccard_postprocessing: 0.969938 train_jaccard_no_postprocessing: 0.593255 train_ans_acc: 0.880931 train_noise_acc: 1.000000
validation loss: 0.495567 eval_jaccard: 0.712153 eval_jaccard_postprocessing: 0.972674 eval_jaccard_no_postprocessing: 0.527951 eval_ans_acc: 0.871156 eval_noise_acc: 1.000000
lr: 0.000044 train loss: 0.586199 train_jaccard: 0.747981 train_jaccard_postprocessing: 0.969844 train_jaccard_no_postprocessing: 0.590030 train_ans_acc: 0.880931 train_noise_acc: 1.000000
lr: 0.000043 train loss: 0.571788 train_jaccard: 0.748217 train_jaccard_postprocessing: 0.970348 train_jaccard_no_postprocessing: 0.589985 train_ans_acc: 0.882413 train_noise_acc: 1.000000
lr: 0.000041 train loss: 0.583810 train_jaccard: 0.748556 train_jaccard_postprocessing: 0.970729 train_jaccard_no_postprocessing: 0.590159 train_ans_acc: 0.881691 train_noise_acc: 1.000000
lr: 0.000040 train loss: 0.562697 train_jaccard: 0.748257 train_jaccard_postprocessing: 0.970368 train_jaccard_no_postprocessing: 0.589825 train_ans_acc: 0.882755 train_noise_acc: 1.000000
validation loss: 0.501555 eval_jaccard: 0.714545 eval_jaccard_postprocessing: 0.972674 eval_jaccard_no_postprocessing: 0.532035 eval_ans_acc: 0.883348 eval_noise_acc: 1.000000
Epoch5

lr: 0.000039 train loss: 0.547411 train_jaccard: 0.759094 train_jaccard_postprocessing: 0.970014 train_jaccard_no_postprocessing: 0.612998 train_ans_acc: 0.888686 train_noise_acc: 1.000000
lr: 0.000037 train loss: 0.529051 train_jaccard: 0.762939 train_jaccard_postprocessing: 0.970301 train_jaccard_no_postprocessing: 0.614778 train_ans_acc: 0.891195 train_noise_acc: 1.000000
lr: 0.000036 train loss: 0.571358 train_jaccard: 0.760369 train_jaccard_postprocessing: 0.968773 train_jaccard_no_postprocessing: 0.616288 train_ans_acc: 0.888078 train_noise_acc: 1.000000
validation loss: 0.505577 eval_jaccard: 0.709712 eval_jaccard_postprocessing: 0.972674 eval_jaccard_no_postprocessing: 0.523784 eval_ans_acc: 0.883894 eval_noise_acc: 1.000000
lr: 0.000035 train loss: 0.542888 train_jaccard: 0.763472 train_jaccard_postprocessing: 0.968519 train_jaccard_no_postprocessing: 0.618538 train_ans_acc: 0.882870 train_noise_acc: 1.000000
lr: 0.000033 train loss: 0.554338 train_jaccard: 0.761389 train_jaccard_postprocessing: 0.970250 train_jaccard_no_postprocessing: 0.610834 train_ans_acc: 0.882299 train_noise_acc: 1.000000
lr: 0.000032 train loss: 0.546608 train_jaccard: 0.760711 train_jaccard_postprocessing: 0.970537 train_jaccard_no_postprocessing: 0.609753 train_ans_acc: 0.883744 train_noise_acc: 1.000000
validation loss: 0.509900 eval_jaccard: 0.712453 eval_jaccard_postprocessing: 0.972674 eval_jaccard_no_postprocessing: 0.528463 eval_ans_acc: 0.877889 eval_noise_acc: 1.000000
lr: 0.000031 train loss: 0.540705 train_jaccard: 0.760846 train_jaccard_postprocessing: 0.969768 train_jaccard_no_postprocessing: 0.610948 train_ans_acc: 0.884711 train_noise_acc: 1.000000
lr: 0.000029 train loss: 0.534265 train_jaccard: 0.762349 train_jaccard_postprocessing: 0.970134 train_jaccard_no_postprocessing: 0.612907 train_ans_acc: 0.883896 train_noise_acc: 1.000000
lr: 0.000028 train loss: 0.553846 train_jaccard: 0.761926 train_jaccard_postprocessing: 0.970327 train_jaccard_no_postprocessing: 0.612665 train_ans_acc: 0.883262 train_noise_acc: 1.000000
lr: 0.000027 train loss: 0.547301 train_jaccard: 0.761296 train_jaccard_postprocessing: 0.970341 train_jaccard_no_postprocessing: 0.611988 train_ans_acc: 0.884124 train_noise_acc: 1.000000
validation loss: 0.505055 eval_jaccard: 0.710653 eval_jaccard_postprocessing: 0.972674 eval_jaccard_no_postprocessing: 0.525391 eval_ans_acc: 0.880801 eval_noise_acc: 1.000000
Epoch6

lr: 0.000025 train loss: 0.502318 train_jaccard: 0.780603 train_jaccard_postprocessing: 0.975761 train_jaccard_no_postprocessing: 0.638391 train_ans_acc: 0.900547 train_noise_acc: 1.000000
lr: 0.000024 train loss: 0.527870 train_jaccard: 0.771930 train_jaccard_postprocessing: 0.971594 train_jaccard_no_postprocessing: 0.625889 train_ans_acc: 0.886177 train_noise_acc: 1.000000
lr: 0.000023 train loss: 0.535495 train_jaccard: 0.769098 train_jaccard_postprocessing: 0.971250 train_jaccard_no_postprocessing: 0.621236 train_ans_acc: 0.888078 train_noise_acc: 1.000000
validation loss: 0.510057 eval_jaccard: 0.711155 eval_jaccard_postprocessing: 0.972674 eval_jaccard_no_postprocessing: 0.526247 eval_ans_acc: 0.879891 eval_noise_acc: 1.000000
lr: 0.000021 train loss: 0.521666 train_jaccard: 0.768677 train_jaccard_postprocessing: 0.971443 train_jaccard_no_postprocessing: 0.622023 train_ans_acc: 0.888914 train_noise_acc: 1.000000
lr: 0.000020 train loss: 0.504052 train_jaccard: 0.768355 train_jaccard_postprocessing: 0.970387 train_jaccard_no_postprocessing: 0.622560 train_ans_acc: 0.889507 train_noise_acc: 1.000000
lr: 0.000019 train loss: 0.533487 train_jaccard: 0.766775 train_jaccard_postprocessing: 0.970673 train_jaccard_no_postprocessing: 0.620358 train_ans_acc: 0.888762 train_noise_acc: 1.000000
validation loss: 0.508704 eval_jaccard: 0.710761 eval_jaccard_postprocessing: 0.972674 eval_jaccard_no_postprocessing: 0.525575 eval_ans_acc: 0.878981 eval_noise_acc: 1.000000
lr: 0.000017 train loss: 0.544490 train_jaccard: 0.767228 train_jaccard_postprocessing: 0.970476 train_jaccard_no_postprocessing: 0.621712 train_ans_acc: 0.888230 train_noise_acc: 1.000000
lr: 0.000016 train loss: 0.501879 train_jaccard: 0.768855 train_jaccard_postprocessing: 0.970308 train_jaccard_no_postprocessing: 0.624679 train_ans_acc: 0.887260 train_noise_acc: 1.000000
lr: 0.000015 train loss: 0.529556 train_jaccard: 0.768587 train_jaccard_postprocessing: 0.970607 train_jaccard_no_postprocessing: 0.625008 train_ans_acc: 0.886912 train_noise_acc: 1.000000
lr: 0.000013 train loss: 0.525154 train_jaccard: 0.769459 train_jaccard_postprocessing: 0.970352 train_jaccard_no_postprocessing: 0.626215 train_ans_acc: 0.887181 train_noise_acc: 1.000000
validation loss: 0.513780 eval_jaccard: 0.713270 eval_jaccard_postprocessing: 0.972674 eval_jaccard_no_postprocessing: 0.529857 eval_ans_acc: 0.881165 eval_noise_acc: 1.000000
Epoch7

lr: 0.000012 train loss: 0.506134 train_jaccard: 0.782675 train_jaccard_postprocessing: 0.971722 train_jaccard_no_postprocessing: 0.650738 train_ans_acc: 0.891423 train_noise_acc: 1.000000
lr: 0.000011 train loss: 0.511795 train_jaccard: 0.779281 train_jaccard_postprocessing: 0.970422 train_jaccard_no_postprocessing: 0.642709 train_ans_acc: 0.889370 train_noise_acc: 1.000000
lr: 0.000009 train loss: 0.507135 train_jaccard: 0.778773 train_jaccard_postprocessing: 0.969802 train_jaccard_no_postprocessing: 0.642068 train_ans_acc: 0.889446 train_noise_acc: 1.000000
validation loss: 0.518982 eval_jaccard: 0.713049 eval_jaccard_postprocessing: 0.972674 eval_jaccard_no_postprocessing: 0.529480 eval_ans_acc: 0.881529 eval_noise_acc: 1.000000
lr: 0.000008 train loss: 0.524124 train_jaccard: 0.775251 train_jaccard_postprocessing: 0.968514 train_jaccard_no_postprocessing: 0.639735 train_ans_acc: 0.888458 train_noise_acc: 1.000000
lr: 0.000007 train loss: 0.500434 train_jaccard: 0.775495 train_jaccard_postprocessing: 0.969296 train_jaccard_no_postprocessing: 0.640444 train_ans_acc: 0.889234 train_noise_acc: 1.000000
lr: 0.000005 train loss: 0.509578 train_jaccard: 0.774605 train_jaccard_postprocessing: 0.969344 train_jaccard_no_postprocessing: 0.638353 train_ans_acc: 0.888762 train_noise_acc: 1.000000
validation loss: 0.519514 eval_jaccard: 0.711487 eval_jaccard_postprocessing: 0.972674 eval_jaccard_no_postprocessing: 0.526814 eval_ans_acc: 0.880073 eval_noise_acc: 1.000000
lr: 0.000004 train loss: 0.476229 train_jaccard: 0.777353 train_jaccard_postprocessing: 0.969533 train_jaccard_no_postprocessing: 0.641523 train_ans_acc: 0.889338 train_noise_acc: 1.000000
lr: 0.000003 train loss: 0.502167 train_jaccard: 0.778944 train_jaccard_postprocessing: 0.969641 train_jaccard_no_postprocessing: 0.643262 train_ans_acc: 0.889884 train_noise_acc: 1.000000
lr: 0.000001 train loss: 0.493767 train_jaccard: 0.779156 train_jaccard_postprocessing: 0.969841 train_jaccard_no_postprocessing: 0.642754 train_ans_acc: 0.889497 train_noise_acc: 1.000000
lr: 0.000000 train loss: 0.501844 train_jaccard: 0.778457 train_jaccard_postprocessing: 0.970360 train_jaccard_no_postprocessing: 0.641443 train_ans_acc: 0.889370 train_noise_acc: 1.000000
validation loss: 0.520955 eval_jaccard: 0.711748 eval_jaccard_postprocessing: 0.972674 eval_jaccard_no_postprocessing: 0.527259 eval_ans_acc: 0.880983 eval_noise_acc: 1.000000

Loading data...Model loaded as /media/jionie/my_disk/Kaggle/Tweet/model/TweetBert/roberta-base-42/fold_3/5954_step_4_epoch.pth.validation loss: 0.491418 eval_jaccard: 0.716121 eval_jaccard_postprocessing: 0.969345 eval_jaccard_no_postprocessing: 0.533969 eval_ans_acc: 0.880801 eval_noise_acc: 1.000000
Validation metric improved (-inf --> 0.716121).  Saving model ...Model saved as /media/jionie/my_disk/Kaggle/Tweet/model/TweetBert/roberta-base-42/fold_3/5954_step_4_epoch.pth.