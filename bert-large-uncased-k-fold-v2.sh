#CUDA_LAUNCH_BLOCKING=1 python training-k-fold-bert-v2.py --fold 0 --model_type "roberta-base" --seed 42 --batch_size 16 --accumulation_steps 1 --Datasampler "None"
#python training-k-fold-bert-v2.py --fold 1 --model_type "roberta-base" --seed 42 --batch_size 16 --accumulation_steps 1 --Datasampler "None"
#python training-k-fold-bert-v2.py --fold 2 --model_type "roberta-base" --seed 42 --batch_size 16 --accumulation_steps 1 --Datasampler "None"
#python training-k-fold-bert-v2.py --fold 3 --model_type "roberta-base" --seed 42 --batch_size 16 --accumulation_steps 1 --Datasampler "None"
#python training-k-fold-bert-v2.py --fold 4 --model_type "roberta-base" --seed 42 --batch_size 16 --accumulation_steps 1 --Datasampler "None"
#
#
python training-k-fold-bert-v2.py --fold 0 --model_type "albert-large-v2" --seed 1997 --batch_size 8 --accumulation_steps 2 --Datasampler "None"
python training-k-fold-bert-v2.py --fold 1 --model_type "albert-large-v2" --seed 1997 --batch_size 8 --accumulation_steps 2 --Datasampler "None"
python training-k-fold-bert-v2.py --fold 2 --model_type "albert-large-v2" --seed 1997 --batch_size 8 --accumulation_steps 2 --Datasampler "None"
python training-k-fold-bert-v2.py --fold 3 --model_type "albert-large-v2" --seed 1997 --batch_size 8 --accumulation_steps 2 --Datasampler "None"
python training-k-fold-bert-v2.py --fold 4 --model_type "albert-large-v2" --seed 1997 --batch_size 8 --accumulation_steps 2 --Datasampler "None"
#
#
#python training-k-fold-bert-v2.py --fold 0 --model_type "bert-base-uncased" --seed 1996 --batch_size 16 --accumulation_steps 1 --Datasampler "None"
#python training-k-fold-bert-v2.py --fold 1 --model_type "bert-base-uncased" --seed 1996 --batch_size 16 --accumulation_steps 1 --Datasampler "None"
#python training-k-fold-bert-v2.py --fold 2 --model_type "bert-base-uncased" --seed 1996 --batch_size 16 --accumulation_steps 1 --Datasampler "None"
#python training-k-fold-bert-v2.py --fold 3 --model_type "bert-base-uncased" --seed 1996 --batch_size 16 --accumulation_steps 1 --Datasampler "None"
#python training-k-fold-bert-v2.py --fold 4 --model_type "bert-base-uncased" --seed 1996 --batch_size 16 --accumulation_steps 1 --Datasampler "None"

#python training-k-fold-bert-v2.py --fold 0 --model_type "albert-xlarge-v2" --seed 2019 --batch_size 4 --accumulation_steps 8 --Datasampler "None"
#python training-k-fold-bert-v2.py --fold 1 --model_type "albert-xlarge-v2" --seed 2019 --batch_size 4 --accumulation_steps 8 --Datasampler "None"
#python training-k-fold-bert-v2.py --fold 2 --model_type "albert-xlarge-v2" --seed 2019 --batch_size 4 --accumulation_steps 8 --Datasampler "None"
#python training-k-fold-bert-v2.py --fold 3 --model_type "albert-xlarge-v2" --seed 2019 --batch_size 4 --accumulation_steps 8 --Datasampler "None"
#python training-k-fold-bert-v2.py --fold 4 --model_type "albert-xlarge-v2" --seed 2019 --batch_size 4 --accumulation_steps 8 --Datasampler "None"


